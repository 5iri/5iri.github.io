{"0": {
    "doc": "ApexCore A RISC-V based CPU",
    "title": "ApexCore A RISC-V based CPU",
    "content": "--[Shri Vishakh Devanand](https://github.com/5iri) --[Aditya Mahajan](https://github.com/aditya200523) --[Shaurya Rane]() ## Understanding the Basics The ApexCore project is an immersive journey into the world of computer architecture and organization (COA). Although the subject is vast and intricate, we, Shri Vishakh Devanand, Aditya Mahajan, and Shaurya Rane, began our exploration by understanding the core components of a CPU. We started with an edX course that, despite being taught in TLVerilog (a newer and less common programming language), provided us with the foundational knowledge necessary to progress. ## A simple breakdown of the CPU ![CPU_FLOWCHART](./../assets/ApexCore/flowchart.png \"The Image shows a simple flowchart of CPU\") To understand the logic of how it works, let's go through the diagram with the flow. 1. Imagine a 32-bit instruction is going through to the CPU. 2. Instructions are stored in Instruction Memory and they are accessed via addresses stored in Program Counter. The instruction received by the decoder to decode the instruction into what generally occurs into 3 or 4 different things. The instruction type is defined by the operation code. * The source values are given as the address of its place in the register, rather than the value itself, or for some instructions there comes something called immediate values, where you don't want to store the value but just use the value for another calculation and lose it. * Then the destination register, where the calculated value is going to be stored until it is stored in memory or discarded. * Then, it goes into the control unit, where it decides what type of calculation is required for this particular instruction and sends it to the ALU to calculate it. 3. Once the final result is received by the control unit, it is then stored in the destination register as instructed. ## What have we done so far We have completed testing RV32-IM extensions under simulation, which introduces new instructions for multiplication and division. Here's a detailed breakdown of our progress: 1. Code Optimization: We revisited the M extension to refine the code, focusing on enhancing efficiency and ensuring proper functionality. 2. Simulation: Using Vivado, we simulated the RV32-IM extensions. The simulation verified that the new instructions for multiplication and division were correctly implemented and functioning as expected. 3. Debugging and Validation: During simulation, we meticulously debugged the code to identify and fix any issues. This process was crucial for validating the correctness of our implementation. 4. Documentation: Alongside coding and simulation, we documented our process and findings. This documentation will serve as a valuable reference for future development and troubleshooting. 5. Preparation for Hardware Testing: We have prepared the code for the upcoming hardware testing phase. This includes ensuring compatibility with our target FPGA platform and setting up the necessary testing environment. ![Simulation](/markdown_files/posts/assets/ApexCore/Simulation.png) ## Plans for the coming days 1. We are about to test the current code on hardware and ensure it works with high confidence. 2. Keep adding more extensions like Atomic and Floating-point extensions to further increase the general usage of the core. 3. Further End Goal of the project to create a soft-core that can be used for other projects, who don't need to build a cpu from scratch in order to do so. ",
    "url": "/markdown_files/posts/content/ApexCore_blog.html",
    
    "relUrl": "/markdown_files/posts/content/ApexCore_blog.html"
  },"1": {
    "doc": "Notes on how are cancer cells grow and spread through the body",
    "title": "Notes on how are cancer cells grow and spread through the body",
    "content": "# Notes on how are cancer cells grow and spread through the body --- ## What are cancer cells? - fuck ups in DNA causes genes to mutate, which makes a particular types of cells to not listen to the conditions for which the genes to mutate. ## How does Cancer grow? - A cancer cell is different from normal ceels because they: - divide out of control - are immature and don't develop into doing their jobs - avoid the immune system. - ignore signals - don't stick to each other very well and can spread to other parts of the body through the blood or lymphatic system - grow into and damage tissues and organs ## How cancer spreads? - Normal spread usually by pushing on normal tissues and growing into a big ball in the same place, this is called local invasion or invasive cancer. - Cancer can also spread from where it first started to other parts of the body. This process is called metastatis. Cancer cells can metastatsize when they break away from the tumour and travel to a new location in the body through the blood or lymphatic system. ## Why does cancer come back sometimes? - even if 1 cancer cell is left begind during cancer treatment, it has the possibility of growing and dividing into a new tumour. - In some cases, treatment may stop working (become resistant) so cancer cells are no longer being destroyed. ## Why use acoustic tweezers? - It produces high and low acoustic pressures, enabling the movement or positioning of target cells with precision. This allows them to be used for manipulating metastasis-related cancer cells. - The flow cytometry results prove that it is non-invasive. - It can be used to isolate circulating tumor cells (CTCs), and enables in developing targeted treatments. ## how to make acoustic tweezers? - The new device works by placing sound-creating transducers on each side of a small square chamber filled with liquid. These four transducers work in step with those directly across from them, forming two pairs. One creates patterns in the chamber horizontally and the other vertically. The interaction of these two complex, quickly changing sound wave patterns creates dynamic abilities never before demonstrated within the field. ## what is acoustic streaming? - Acoustic streaming is another important principle that underlies acoustic tweezers. When a sound wave passes through a fluid medium, it creates tiny vortexes of fluid around the edges of the wave. These vortexes can be used to move small objects within the fluid, even against the direction of the sound wave itself. ## Use cases other than biomedicine - In microelectronics, acoustic tweezers have the potential to revolutionize the manufacturing process for microchips and other tiny electronic components. By using sound waves to position and manipulate these components, researchers can improve the accuracy and efficiency of the manufacturing process. - ## resources - [How cancer starts, grows and spreads](https://cancer.ca/en/cancer-information/what-is-cancer/how-cancer-starts-grows-and-spreads) - [acoustic tweezers](https://acoustofluidics.pratt.duke.edu/research/acoustic-tweezers) - [Cells Dancing to Harmonic Duets Could Enable Personalized Cancer Therapies](https://pratt.duke.edu/news/harmonic-acoustic-tweezers/) ",
    "url": "/markdown_files/posts/content/basics_of_cancer_cells.html",
    
    "relUrl": "/markdown_files/posts/content/basics_of_cancer_cells.html"
  },"2": {
    "doc": "Requirements, Bottlenecks, and Good Fortune: Agents for Microprocessor Evolution",
    "title": "Requirements, Bottlenecks, and Good Fortune: Agents for Microprocessor Evolution",
    "content": "# Requirements, Bottlenecks, and Good Fortune: Agents for Microprocessor Evolution ``` by yale patt ``` ## Basic Framework - Computer Architecture: A science of tradeoffs - Comp arch is more \"art\" than \"science\" - Almost always the job of the comp architect requires using that fundamental knowledge to make tradeoffs. - Levels of Transformation - There are levels of transformations that is being done whenever there's a high level program that is being done. - Like take for example a C code, it first compiles into an assembly code (a lot more process that happens but not imp here). - This \"assembly\" code is basically converted into where ISA structure is used, where ISA defines on how the assembly code is being defined. - Now, Even though the \"assembly\" code is now converted into something in binary, how this binary is being processed is (which bits need to go where in order for the \"assembly\" line to be processed actually) [Instruction is being processed] - This is called microarchitecture. - This microarchitecture is defined by actual electronic circuit design, and in the end electrons. - These are the levels of transformation that occurs from any problem to actually making it solve by a circuit (or by electrons). ![Levels of Transformation](/markdown_files/posts/assets/comparchreads/image1.png) - Design Points - When working in the microarchitecture part, there is always a purpose towards what you are trying to achieve. - This is called the Design Point. - It could be something like, making a core more power efficient , fault tolerant (server chips), highest power etc. - Application Space - Sometimes the chips that we design are application specific, and sometimes generalistic in nature, this is what we call application space here. - The Basics of Processing - Simply put, a microprocessor processes instructions. - To do this, it has to do three things: - Supply instructions to the core of the processor where the instructions are executed. - Supply data required for the instructions - Perform the operation required by each instruction. - Instruction Supply - fetching one instruction at a time is slow when processors are getting faster and better at processing them. - So, the fetching of instructions should be done in parallel, making it more efficient. - Data Supply - Once the instruction is fetched, the data required for the instruction is supplied to the processor. - This must be done in a fast manner as well. - So faster caches (on-chip RAM) are used to supply the data for a particular instruction. - Instruction Processing - Once the instruction is fetched and the data is supplied, the instruction must also be processed fast. - To perform the operations required by these instructions, the processor needs a sufficient number of functional units to process the data. ## Agents for Evolution - The creativity of engineers to come up with answers where there were problems--- without solutions, there would be no Evolution. - Agent I: New Requirements - The demand for higher performance dictated that fetching one instruction at a time was not enough. - Examples like this forces evolution and creative solution thinking. - Agent II: Bottlenecks - We have 3 components of instruction processing (instruction supply, data supply, and carrying out the operations of the instruction). - By far, most of the improvements to the microprocessor have come about due to attempts to eliminate bottlenecks that prevent these components from being fully utilized. - Agent III: Good Fortune - Good Fortune happens when something causes a windfall which can then be used to provide additional features to the microprocessor. ",
    "url": "/markdown_files/posts/content/comparchreads1.html",
    
    "relUrl": "/markdown_files/posts/content/comparchreads1.html"
  },"3": {
    "doc": "Memory Performance Attacks: Denial of Memory Service in Multi-Core Systems",
    "title": "Memory Performance Attacks: Denial of Memory Service in Multi-Core Systems",
    "content": "# Memory Performance Attacks: Denial of Memory Service in Multi-Core Systems **Thomas Moscibroda** **Onur Mutlu** @microsoft ## Introduction - The transition from single-core to multi-core systems has introduced major performance and security challenges. - Multiple programs running on shared DRAM systems can interfere with each other's memory accesses, leading to performance degradation and security vulnerabilities. - This paper introduces a new security problem that arises due to the core design of multi-core architectures – a denial of service (DoS) attack that was not possible in single-core systems. - An aggressive memory-intensive program can severely impact the performance of other threads with which it is co-scheduled. This is called a Memory Performance Hog (MPH). - This problem worsens with an increasing number of cores, as the impact grows exponentially. - An MPH can be used to perform DoS attacks that fool users into thinking other applications are inherently slow, even without causing easily observable performance issues. - A regular application can unintentionally behave like an MPH and damage the memory-related performance of co-scheduled threads. ## DRAM Architectures - DRAM memory is an expensive resource in modern systems. Creating a separate DRAM system for each core is not feasible. - In a partitioned DRAM system, a processor accessing a memory location needs to issue a request to the DRAM partition that contains the data for that location. ## DRAM Memory Systems ![DRAM BANK ORGANIZATION](posts/assets/DRAM_block_diagram.png) - **Row Hit:** Accessing a row already in the row-buffer. It has the lowest latency (around 40-50 ns in commodity DRAM). - **Row Conflict:** Accessing a different row than the one currently in the row-buffer, requiring the row-buffer to be written back before the new row can be accessed. - **Row Closed:** No row in the row-buffer, necessitating a read from the memory array before column access. ## DRAM Controller - The DRAM controller mediates between on-chip caches and off-chip DRAM memory. It receives read/write requests from L2 caches. - The **memory access scheduler** is responsible for selecting memory requests from the memory request buffer to send to the DRAM memory. ## Memory Access Scheduling Algorithm - Current memory access schedulers typically employ the **First-Ready First-Come-First-Serve (FR-FCFS)** algorithm, which prioritizes requests in the following order: - **Row-hit first:** Prioritizes requests that hit the row already in the row-buffer. - **Oldest-within-bank first:** Prioritizes requests that arrived earliest within the same bank. - **Oldest-across-banks first:** Prioritizes the earliest arrival time among requests selected by individual bank schedulers. ## Vulnerabilities of Multi-Core DRAM Memory System to DoS Attacks - Current DRAM memory systems do not distinguish between the requests of different threads. - **Unfairness of Row-Hit First Scheduling:** A thread whose accesses result in row hits gets higher priority compared to a thread whose accesses result in row conflicts. - **Unfairness of Oldest-First Scheduling:** Oldest-first scheduling implicitly favors threads that can generate memory requests at a faster rate than others. ## Examples of DoS in Existing Multi-Cores - When two threads use different access patterns, such as one streaming data and the other accessing memory randomly, the memory controller will prioritize the one with the optimized memory access pattern. ## Fairness in DRAM Memory Systems - Defining fairness in DRAM systems is complex, and coming up with a reasonable definition is challenging. ## Fair Memory Scheduling: A Model - The authors propose a model for fair memory scheduling to mitigate the impact of MPHs. - **Fairness Definition:** A memory scheduler is fair if equal-priority threads experience the same memory-related slowdowns when running together. - **Stall-Time Fair Memory Scheduler (STFM):** STFM prioritizes threads based on their stall times, ensuring that no thread monopolizes memory resources, thus promoting fairness. - **Implementation Considerations:** STFM requires modifications to the memory controller to track stall times for each thread, ensuring equitable memory access for co-scheduled threads. ## Conclusion - The paper highlights the vulnerabilities of multi-core systems to DoS attacks due to unfair memory access scheduling. - By introducing the concept of Memory Performance Hogs and the Stall-Time Fair Memory Scheduler, the authors offer a framework to enhance fairness and improve both the performance and security of multi-core systems. ",
    "url": "/markdown_files/posts/content/memory_performance_attacks.html",
    
    "relUrl": "/markdown_files/posts/content/memory_performance_attacks.html"
  },"4": {
    "doc": "About Me",
    "title": "About Me",
    "content": "# About Me Hello! I'm **Shri Vishakh Devanand**, a sophomore Electrical Engineering student from India with a profound love for mathematics. My academic journey is driven by a relentless curiosity to understand and innovate at the intersection of hardware and software. I specialize in designing novel solutions in VLSI, robotics, embedded systems, and lithography, always striving to bridge theoretical concepts with practical applications. ## What I Do - **Digital Design Enthusiast**: Developed a fully functional RISC-V CPU on FPGA from scratch, focusing on low-level digital design and computer architecture. Currently engaged in formal verification of the same CPU. - **Embedded Systems Developer**: Building RTOS solutions for ESP32, emphasizing advanced features like task scheduling, context switching, and interrupt service routines. - **Robotics Innovator**: Developing resilient robotic systems, including a 3-DOF manipulator and a bio-inspired turtle-like robot for habitat observation. - **Lithography Researcher**: Exploring advanced lithographic techniques to enhance semiconductor fabrication processes, aiming to improve resolution and efficiency in microfabrication. - **Sustainability Advocate**: Actively contributing to environmental initiatives, including beach cleanup projects, committed to creating a lasting positive impact. ## My Vision I am determined to create bold solutions that bridge the gap between breakthrough technologies and real-world challenges. My focus is on advancing VLSI design, optimizing robotics control systems for energy-efficient devices, and innovating in lithographic processes to push the boundaries of microfabrication. I believe in embracing continuous learning and pushing the boundaries of innovation. ## Some Fun Facts About Me - I have a profound love for mathematics, and I love delving deep into various abstract concepts, especially complex analysis. - I'm passionate about mentoring and teaching, imparting robotics and automation skills to freshmen at the university. - I thrive on creativity in my designs, believing that brainstorming unconventional ideas leads to groundbreaking solutions. ## Contact Me Feel free to reach out to me through the following channels: - **Email**: [shrivishakhdevanand@gmail.com](mailto:shrivishakhdevanand@gmail.com) I look forward to connecting with like-minded individuals and exploring collaborative opportunities. ",
    "url": "/",
    
    "relUrl": "/"
  }
}
